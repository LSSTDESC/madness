{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 01:16:45.000111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-26 01:16:45.207201: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-26 01:16:45.213852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /pbs/throng/lsst/users/bbiswas/miniconda3/envs/madness/lib/:\n",
      "2024-03-26 01:16:45.213883: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-26 01:16:47.820888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /pbs/throng/lsst/users/bbiswas/miniconda3/envs/madness/lib/:\n",
      "2024-03-26 01:16:47.821012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /pbs/throng/lsst/users/bbiswas/miniconda3/envs/madness/lib/:\n",
      "2024-03-26 01:16:47.821026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-26 01:16:56.014449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /pbs/throng/lsst/users/bbiswas/miniconda3/envs/madness/lib/:\n",
      "2024-03-26 01:16:56.014504: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-26 01:16:56.014540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jns-bbiswas.cc.in2p3.fr): /proc/driver/nvidia/version does not exist\n",
      "2024-03-26 01:16:56.017196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from madness_deblender.callbacks import define_callbacks\n",
    "from madness_deblender.FlowVAEnet import FlowVAEnet\n",
    "from madness_deblender.losses import (\n",
    "    deblender_encoder_loss_wrapper,\n",
    "    deblender_loss_fn_wrapper,\n",
    ")\n",
    "from madness_deblender.utils import get_data_dir_path\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Creating toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_noisy_galaxies = np.random.rand(8, 11, 11, 6)\n",
    "noiseless_galaxies = np.random.rand(8, 11, 11, 6)\n",
    "blended_galaxies = np.random.rand(8, 11, 11, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_prior = tfd.Independent(\n",
    "    tfd.Normal(loc=tf.zeros(1), scale=1), reinterpreted_batch_ndims=1\n",
    ")\n",
    "\n",
    "f_net = FlowVAEnet(\n",
    "    stamp_shape=11,\n",
    "    latent_dim=4,\n",
    "    filters_encoder=[1, 1, 1, 1],\n",
    "    filters_decoder=[1, 1, 1],\n",
    "    kernels_encoder=[1, 1, 1, 1],\n",
    "    kernels_decoder=[1, 1, 1],\n",
    "    dense_layer_units=1,\n",
    "    num_nf_layers=1,\n",
    "    kl_prior=kl_prior,\n",
    "    kl_weight=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Train VAE as a denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 11, 11, 6)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 14)                95        \n",
      "                                                                 \n",
      " latent_space (MultivariateN  ((None, 4),              0         \n",
      " ormalTriL)                   (None, 4))                         \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 11, 11, 6)         686       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 781\n",
      "Trainable params: 781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training only VAE network ---\n",
      "Encoder status: True\n",
      "Decoder status: True\n",
      "Number of epochs: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_mse improved from inf to 0.33006, saving model to /pbs/throng/lsst/users/bbiswas/FlowDeblender/madness_deblender/data/test_temp/vae/val_mse/weights.ckpt\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 139.52112, saving model to /pbs/throng/lsst/users/bbiswas/FlowDeblender/madness_deblender/data/test_temp/vae/val_loss/weights.ckpt\n",
      "1/1 - 13s - loss: 140.9377 - mse: 0.3318 - kl_metric: 1.2343 - val_loss: 139.5211 - val_mse: 0.3301 - val_kl_metric: 0.3328 - lr: 4.0000e-06 - 13s/epoch - 13s/step\n"
     ]
    }
   ],
   "source": [
    "vae_epochs = 2\n",
    "\n",
    "data = np.random.rand(8, 11, 11, 6)\n",
    "\n",
    "# Keras Callbacks\n",
    "data_path = get_data_dir_path()\n",
    "\n",
    "path_weights = os.path.join(data_path, \"test_temp\")\n",
    "callbacks = define_callbacks(\n",
    "    os.path.join(path_weights, \"vae\"),\n",
    "    lr_scheduler_epochs=1,\n",
    "    patience=1,\n",
    ")\n",
    "\n",
    "_ = f_net.train_vae(\n",
    "    (isolated_noisy_galaxies[:6], noiseless_galaxies[:6]),  # training\n",
    "    (isolated_noisy_galaxies[6:], noiseless_galaxies[6:]),  # validation\n",
    "    callbacks=callbacks,\n",
    "    epochs=int(0.5 * vae_epochs),\n",
    "    train_encoder=True,\n",
    "    train_decoder=True,\n",
    "    track_kl=True,\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5, clipvalue=0.1),\n",
    "    loss_function=deblender_loss_fn_wrapper(\n",
    "        sigma_cutoff=np.array([1] * 6),  # Noise level in the data\n",
    "        linear_norm_coeff=1,  # coefficient of linear normalization\n",
    "    ),\n",
    "    verbose=2,\n",
    "    # loss_function=vae_loss_fn_wrapper(sigma=noise_sigma, linear_norm_coeff=linear_norm_coeff),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Train Normalizing Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_net.load_vae_weights(os.path.join(path_weights, \"vae\", \"val_loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 11, 11, 6)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 14)                95        \n",
      "                                                                 \n",
      " latent_space (MultivariateN  ((None, 4),              0         \n",
      " ormalTriL)                   (None, 4))                         \n",
      "                                                                 \n",
      " flow (Functional)           (None,)                   1480      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,575\n",
      "Trainable params: 1,480\n",
      "Non-trainable params: 95\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training only FLOW network ---\n",
      "Number of epochs: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 01:17:14.549759: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fde64074410 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-26 01:17:14.549836: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Host, Default Version\n",
      "2024-03-26 01:17:18.909241: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 5.64812, saving model to /pbs/throng/lsst/users/bbiswas/FlowDeblender/madness_deblender/data/test_temp/flow/val_loss/weights.ckpt\n",
      "1/1 - 10s - loss: 5.8650 - val_loss: 5.6481 - lr: 4.0000e-05 - 10s/epoch - 10s/step\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 5.64812 to 3.84261, saving model to /pbs/throng/lsst/users/bbiswas/FlowDeblender/madness_deblender/data/test_temp/flow/val_loss/weights.ckpt\n",
      "1/1 - 0s - loss: 5.5881 - val_loss: 3.8426 - lr: 1.6000e-05 - 137ms/epoch - 137ms/step\n"
     ]
    }
   ],
   "source": [
    "flow_epochs = 2\n",
    "\n",
    "callbacks = define_callbacks(\n",
    "    os.path.join(path_weights, \"flow\"),\n",
    "    lr_scheduler_epochs=1,\n",
    "    patience=1,\n",
    ")\n",
    "\n",
    "hist_flow = f_net.train_flow(\n",
    "    (\n",
    "        isolated_noisy_galaxies[:6],\n",
    "        np.zeros_like(isolated_noisy_galaxies[:6]),\n",
    "    ),  # training\n",
    "    (\n",
    "        isolated_noisy_galaxies[6:],\n",
    "        np.zeros_like(isolated_noisy_galaxies[6:]),\n",
    "    ),  # validation\n",
    "    callbacks=callbacks,\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4, clipvalue=0.01),\n",
    "    epochs=flow_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Train VAE-deblender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_net_original = FlowVAEnet(\n",
    "    stamp_shape=11,\n",
    "    latent_dim=4,\n",
    "    filters_encoder=[1, 1, 1, 1],\n",
    "    filters_decoder=[1, 1, 1],\n",
    "    kernels_encoder=[1, 1, 1, 1],\n",
    "    kernels_decoder=[1, 1, 1],\n",
    "    dense_layer_units=1,\n",
    "    num_nf_layers=1,\n",
    "    kl_prior=kl_prior,\n",
    "    kl_weight=1,\n",
    ")\n",
    "f_net_original.load_vae_weights(os.path.join(path_weights, \"vae\", \"val_loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = define_callbacks(\n",
    "    os.path.join(path_weights, \"deblender\"),\n",
    "    lr_scheduler_epochs=1,\n",
    "    patience=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 11, 11, 6)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 6, 6, 1)           7         \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, 6, 6, 1)           36        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 3, 1)           2         \n",
      "                                                                 \n",
      " p_re_lu_1 (PReLU)           (None, 3, 3, 1)           9         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 1)           2         \n",
      "                                                                 \n",
      " p_re_lu_2 (PReLU)           (None, 2, 2, 1)           4         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 1)           2         \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, 1, 1, 1)           1         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1)                 0         \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, 1)                 1         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 1)                 1         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95\n",
      "Trainable params: 0\n",
      "Non-trainable params: 95\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training only encoder network ---\n",
      "Number of epochs: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.20393, saving model to /pbs/throng/lsst/users/bbiswas/FlowDeblender/madness_deblender/data/test_temp/deblender/val_loss/weights.ckpt\n",
      "1/1 - 3s - loss: 4.3347 - val_loss: 2.2039 - lr: 4.0000e-06 - 3s/epoch - 3s/step\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can save best model only with val_mse available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 2.20393\n",
      "1/1 - 0s - loss: 4.1083 - val_loss: 2.7837 - lr: 1.6000e-06 - 40ms/epoch - 40ms/step\n"
     ]
    }
   ],
   "source": [
    "hist_deblender = f_net.train_encoder(\n",
    "    (blended_galaxies[:6], isolated_noisy_galaxies[:6]),  # training\n",
    "    (blended_galaxies[6:], isolated_noisy_galaxies[6:]),  # validation\n",
    "    callbacks=callbacks,\n",
    "    epochs=2,\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5, clipvalue=0.1),\n",
    "    loss_function=deblender_encoder_loss_wrapper(\n",
    "        original_encoder=f_net_original.encoder,\n",
    "        noise_sigma=np.array([1] * 6),\n",
    "        latent_dim=4,\n",
    "    ),\n",
    "    verbose=2,\n",
    "    # loss_function=vae_loss_fn_wrapper(sigma=noise_sigma, linear_norm_coeff=linear_norm_coeff),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madness",
   "language": "python",
   "name": "madness"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
